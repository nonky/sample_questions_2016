
When deriving Simpson's rule, we saw in class that the area under a
parabola dx wide is dx*(f_left+4*f_mid+f_right).  Write a python
routine to integrate 1/(1+x^2) using Simpson's rule from -10 to 10,
but one that accepts as input an arbitrary set of positions for the
bin edges.  You may assume you get f_left/right passed to you, and you
calculate the position of f_mid.  Run with bins that are 0.1 wide
between -1 and 1, and 1 wide otherwise.  Compare that to the answer
with bins 0.1 wide over the entire region from -10 to 10.

see simpson_varying.py

--------------------------------------------------------------------------------


Simpson's rule works by fitting a parabola to 3 points.  If we wished
to have higher-order accurate integration, one thing we could do is to
fit a higher-order polynomial.  We can use least-squares fitting to
fit a polynomial to a region, then do the integral on the polynomial
to get the set of weights for each data point.  For reference, the set
of weights for Simpson's rule is (1,4,1)/6.  

see get_poly_weights.py

--------------------------------------------------------------------------------

multi-dimensional discrete Fourier Transforms are frequently used in
scientific computing.  Write down the equations for a 2-dimensional
DFT.  Show that it can be done as a series of 1-D DFTs.  If you have
an N by M array, how does the operation count for a 2-D FFT scale with
N and M?  You may ignore any multiplicative constants.


2d DFT is sum_x sum_y(f(x,y)*exp(-2*pi*i/N(x*k+y*l))
exponential term splits up:
sum_x sum_y(f(x,y)*exp(-2*pi*i/N*(kx))*exp(-2*pi*i/N*(yl)))
can reorder to pull the x part out of the inside sum:

sum_x exp(-2*pi*i/N*kx) sum_y f(x,y) exp(-2*pi*i/N*yl)

the inside sum is just the Fourier transform along the y direction.  
the outside sum is now just the Fourier transform along the x direction
of all the y-direction Fourier transforms.

--------------------------------------------------------------------------------



Let's compare mesh-based and particle-based methods for doing N-body
simulations in two dimensions.  Let's say we have N particles, and
our mesh is m cells on a side, so a total of m^2 cells.  Furthermore,
let's assume that for a mesh-based gravity solver, the work is
dominated by the FFT (i.e. the placing of the N particles onto the
grid is negligible).  Let's say that the total computational work
required for a particle-particle solver is a*f(N), where 'a' is a
constant, and f(N) is some function of N - for instance, if adding new
particles required a linear amount of extra work, f(N) would be equal
to N^1.  What is f(N)?  Next, let the work for the grid-based solver
be bg(m), again for some unknown constant 'b'.  What is g(m)?
Finally, combine these results to find the number of particles at
which the work required for an direct force calculation and a grid
calculation are equal.  If you have more particles than this critical
value, would it be faster to use a grid-based or a direct gravity calculator?


answer:
number of particle interations goes like n^2, so f(n)=n^2

technically, g(m) scales like log(m^2)*m^2, since we have to FFT m^2 points, but for any 
reasonable value of m, log(m) is effectively constant, e.g. only changes by a factor of 3 
when going from 1,000 to 1,000,000. 

Total work is equal when a*n^2=b*m^2, or n=m*sqrt(b/a)
sqrt(b/a) is some number of order unity, so the break point is around 
averaging one number per cell.  If we increase the number of particles while keeping 
the number of cells fixed, the particle calculation becomes slower and we should 
switch to the grid.  Note that this is not true in 3 dimensions - think about how that would work.


--------------------------------------------------------------------------------


model fitting:  we saw in class that if you have data that depend
linearly on a model, <d>=Am, that chi^2 can be written down as
(d-Am)^T N^-1 (d-Am).  Show that this has solution
m=(A^T N^-1 A)^-1 A^T N^-1 d
If we assume the noise is constant, that reduces to 
m=(A^T A)^-1 A^T d.  


the math is worked out in the model fitting slides.  If the noise is constant, then
N =nI for some scalar n and identity matrix I.  In that case, the n can be factored out leaving
m=(A^T 1/n I A)^-1 A^T 1/n I d
1/n inside the inverse becomes n again, and we can drop the I's, since they have no effect.
Leaves:  m=n (A^T A)^-1 A^T 1/n d
The n and 1/n cancel, leaving 
m=(A^T A)^-1 A^T d

--------------------------------------------------------------------------------


This is often used to fit polynomials to data models.  However, for
some classes of functions, other basis sets may be more useful.  
Fit e^-x between 1 and 5 (using at least 100 points) using x^-n for
your basis functions (i.e. columns of A) with n an integer, ranging
from 0 to 5 (i.e. x^0, x^-1...x^-5).  Recall that numpy.dot will do a
matrix multiply of arrays, alternatively numpy.matrix will turn an
array into a matrix.

see fit_exponential.py


--------------------------------------------------------------------------------


MCMC:  Take the output Markov chain from the class MCMC example.  As
discussed in class, its power spectrum (the absolute value of its
Fourier transform squared) should be flat at low frequencies and slope
down at high frequencies.  Do you see that?  If not, why might that be the case?


look at analyze_chain.py.  You'll see that for this chain and parameter 0, there's 
a pronounced kink in the Fourier transform at around frequency 100-200.  So, we have a good idea that  
the chain has at least a few hundred independent samples, and therefore the mean 
is probably well converged along with the standard deviations.  Would you trust the 3-sigma 
statistics from this chain?
